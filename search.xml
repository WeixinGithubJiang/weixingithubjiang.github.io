<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Paper List</title>
    <url>/2020/07/01/papers/</url>
    <content><![CDATA[<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>The PhD study is a period of accumulation, we read papers, take notes, come up with ideas, validate the effectiveness of the ideas, write papers. We need to take the same process again and again, which is not fun, and sometimes even desperate. Luckily, right now, I am still able to say that, I enjoy learning, learning any kind of new knowledge. In this blog, I would like to keep a record of papers that are interesting to me. Maybe I will take notes for some papers, maybe not.</p>
<a id="more"></a>
<h2 id="PAPER-ID-1"><a href="#PAPER-ID-1" class="headerlink" title="PAPER ID 1"></a>PAPER ID 1</h2><p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/He_Local_Descriptors_Optimized_CVPR_2018_paper.pdf" target="_blank" rel="noopener">He, Kun, Yan Lu, and Stan Sclaroff. “Local descriptors optimized for average precision.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.</a></p>
]]></content>
      <categories>
        <category>Interesting Papers</category>
      </categories>
      <tags>
        <tag>Notes</tag>
        <tag>2020</tag>
        <tag>PhD study</tag>
      </tags>
  </entry>
  <entry>
    <title>Image Retrieval</title>
    <url>/2020/06/14/machine_learning_notes_5/</url>
    <content><![CDATA[<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>Image retrieval is a very popular topic in the field of information retrieval. The goal of image retrieval is to locate an image in the database which is most similar to the given query.</p>
<a id="more"></a>
<h2 id="CONTENT-BASED-IMAGE-RETRIEVAL-WITH-LOCAL-FEATURES"><a href="#CONTENT-BASED-IMAGE-RETRIEVAL-WITH-LOCAL-FEATURES" class="headerlink" title="CONTENT BASED IMAGE RETRIEVAL WITH LOCAL FEATURES"></a>CONTENT BASED IMAGE RETRIEVAL WITH LOCAL FEATURES</h2><p><a href="https://link.springer.com/content/pdf/10.1023/B:VISI.0000029664.99615.94.pdf" target="_blank" rel="noopener">Lowe, David G. “Distinctive image features from scale-invariant keypoints.” International journal of computer vision 60.2 (2004): 91-110.</a></p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544890&casa_token=gZxoUlD3j38AAAAA:plZVebfKb556v63t63w0NRonbh-5WQk_acqnxWGGZ1XUgFfJxO1_vHj99iynJm8e9HOjsSZ8Ukc" target="_blank" rel="noopener">Grauman, Kristen, and Trevor Darrell. “The pyramid match kernel: Discriminative classification with sets of image features.” Tenth IEEE International Conference on Computer Vision (ICCV’05) Volume 1. Vol. 2. IEEE, 2005.</a></p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1641019&casa_token=z7mW60gG_ooAAAAA:QxtGf8VvDphxOGuTBJKfBkvmRZbMid7qDMeYskdOi5OwOCCNsDZ4C-p5P8dVylwqOaLUR9RKT7U" target="_blank" rel="noopener">Lazebnik, Svetlana, Cordelia Schmid, and Jean Ponce. “Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories.” 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’06). Vol. 2. IEEE, 2006.</a></p>
<h2 id="CONTENT-BASED-IMAGE-RETRIEVAL-WITH-CNN"><a href="#CONTENT-BASED-IMAGE-RETRIEVAL-WITH-CNN" class="headerlink" title="CONTENT BASED IMAGE RETRIEVAL WITH CNN"></a>CONTENT BASED IMAGE RETRIEVAL WITH CNN</h2><p><a href="https://arxiv.org/pdf/1511.05879.pdf" target="_blank" rel="noopener">Tolias, Giorgos, Ronan Sicre, and Herve Jegou. “Particular object retrieval with integral max-pooling of CNN activations.” arXiv preprint arXiv:1511.05879 (2015).</a></p>
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Revaud_Learning_With_Average_Precision_Training_Image_Retrieval_With_a_Listwise_ICCV_2019_paper.pdf" target="_blank" rel="noopener">Revaud, Jerome, et al. “Learning with average precision: Training image retrieval with a listwise loss.” Proceedings of the IEEE International Conference on Computer Vision. 2019.</a></p>
<p><a href="https://link.springer.com/content/pdf/10.1007/s11263-017-1016-8.pdf" target="_blank" rel="noopener">Gordo, Albert, et al. “End-to-end learning of deep visual representations for image retrieval.” International Journal of Computer Vision 124.2 (2017): 237-254.</a></p>
<p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Radenovic_Revisiting_Oxford_and_CVPR_2018_paper.pdf" target="_blank" rel="noopener">Radenovi?, Filip, et al. “Revisiting oxford and paris: Large-scale image retrieval benchmarking.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.</a></p>
]]></content>
      <categories>
        <category>Machine Learning Notes</category>
      </categories>
      <tags>
        <tag>Notes</tag>
        <tag>Machine Learning</tag>
        <tag>2020</tag>
      </tags>
  </entry>
  <entry>
    <title>Recursive Neural Network</title>
    <url>/2020/06/05/machine_learning_notes_3/</url>
    <content><![CDATA[<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>Recursive Neural Network (RNN) has been widely used in different fields and makes contribution to the development of deep learning. The most interesting part of RNN is its capacity of handling time-sequence data, taking the order of data blocks into account. Some interesting work is posted below.</p>
<a id="more"></a>
<h2 id="MACHINE-TRANSLATION"><a href="#MACHINE-TRANSLATION" class="headerlink" title="MACHINE TRANSLATION"></a>MACHINE TRANSLATION</h2><p><a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. “Sequence to sequence learning with neural networks.” Advances in neural information processing systems. 2014.</a></p>
<h2 id="FEATURE-PAPER"><a href="#FEATURE-PAPER" class="headerlink" title="FEATURE PAPER"></a>FEATURE PAPER</h2><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.676.4320&rep=rep1&type=pdf" target="_blank" rel="noopener">Hochreiter, Sepp, and Jurgen Schmidhuber. “Long short-term memory.” Neural computation 9.8 (1997): 1735-1780.</a></p>
]]></content>
      <categories>
        <category>Machine Learning Notes</category>
      </categories>
      <tags>
        <tag>Notes</tag>
        <tag>Machine Learning</tag>
        <tag>2020</tag>
      </tags>
  </entry>
  <entry>
    <title>Object Detection</title>
    <url>/2020/06/05/machine_learning_notes_4/</url>
    <content><![CDATA[<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>Object detection is one of the most important but fundamental tasks in the field of computer vision. The goal of the object detection is to locate objects of interest and recognize them. Some feature work is shown below.</p>
<a id="more"></a>
<h2 id="REGULAR-OBJECT-DETECTION"><a href="#REGULAR-OBJECT-DETECTION" class="headerlink" title="REGULAR OBJECT DETECTION"></a>REGULAR OBJECT DETECTION</h2><p><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Lin, Tsung-Yi, et al. “Feature pyramid networks for object detection.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.</a></p>
<p><a href="https://arxiv.org/pdf/1512.02325.pdf" target="_blank" rel="noopener">Liu, Wei, et al. “Ssd: Single shot multibox detector.” European conference on computer vision. Springer, Cham, 2016.</a></p>
<h2 id="SCENE-TEXT-DETECTION"><a href="#SCENE-TEXT-DETECTION" class="headerlink" title="SCENE TEXT DETECTION"></a>SCENE TEXT DETECTION</h2><p><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16469/16260" target="_blank" rel="noopener">Deng, Dan, et al. “Pixellink: Detecting scene text via instance segmentation.” Thirty-second AAAI conference on artificial intelligence. 2018.</a></p>
<p><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Shi_Detecting_Oriented_Text_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Shi, Baoguang, Xiang Bai, and Serge Belongie. “Detecting oriented text in natural images by linking segments.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.</a></p>
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Baek_Character_Region_Awareness_for_Text_Detection_CVPR_2019_paper.pdf" target="_blank" rel="noopener">Baek, Youngmin, et al. “Character region awareness for text detection.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.</a></p>
]]></content>
      <categories>
        <category>Machine Learning Notes</category>
      </categories>
      <tags>
        <tag>Notes</tag>
        <tag>Machine Learning</tag>
        <tag>2020</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning to learn</title>
    <url>/2020/06/03/machine_learning_notes_2/</url>
    <content><![CDATA[<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>Learning to learn (i.e. meta learning, few-shot learning) is a set of learning methods, which tries to exploit the previous experience on other tasks to facilitate the learning process on the current task. Some interesting paper about few-shot learning/meta-learning are posted below.</p>
<a id="more"></a>
<h2 id="OBJECT-DETECTION"><a href="#OBJECT-DETECTION" class="headerlink" title="OBJECT DETECTION"></a>OBJECT DETECTION</h2><p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Kang_Few-Shot_Object_Detection_via_Feature_Reweighting_ICCV_2019_paper.pdf" target="_blank" rel="noopener">Kang, Bingyi, et al. “Few-shot object detection via feature reweighting.” Proceedings of the IEEE International Conference on Computer Vision. 2019.</a></p>
<h2 id="SEGMENTATION"><a href="#SEGMENTATION" class="headerlink" title="SEGMENTATION"></a>SEGMENTATION</h2><p><a href="https://arxiv.org/pdf/1611.05198.pdf" target="_blank" rel="noopener">Caelles, Sergi, et al. “One-shot video object segmentation.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.</a></p>
<p><a href="https://arxiv.org/pdf/1709.03410.pdf" target="_blank" rel="noopener">Shaban, Amirreza, et al. “One-shot learning for semantic segmentation.” arXiv preprint arXiv:1709.03410 (2017).</a></p>
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_PANet_Few-Shot_Image_Semantic_Segmentation_With_Prototype_Alignment_ICCV_2019_paper.pdf" target="_blank" rel="noopener">Wang, Kaixin, et al. “Panet: Few-shot image semantic segmentation with prototype alignment.” Proceedings of the IEEE International Conference on Computer Vision. 2019.</a></p>
<p><a href="https://arxiv.org/pdf/1810.09091.pdf" target="_blank" rel="noopener">Zhang, Xiaolin, et al. “Sg-one: Similarity guidance network for one-shot semantic segmentation.” arXiv preprint arXiv:1810.09091 (2018).</a></p>
<h2 id="LOW-LEVEL-COMPUTER-VISION"><a href="#LOW-LEVEL-COMPUTER-VISION" class="headerlink" title="LOW-LEVEL COMPUTER VISION"></a>LOW-LEVEL COMPUTER VISION</h2><p><a href="https://arxiv.org/pdf/1908.00111.pdf" target="_blank" rel="noopener">Casas, Leslie, et al. “Few-Shot Meta-Denoising.” arXiv preprint arXiv:1908.00111 (2019).</a></p>
<h2 id="OPTIMIZATION"><a href="#OPTIMIZATION" class="headerlink" title="OPTIMIZATION"></a>OPTIMIZATION</h2><p><a href="http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf" target="_blank" rel="noopener">Vinyals, Oriol, et al. “Matching networks for one shot learning.” Advances in neural information processing systems. 2016.</a></p>
<p><a href="https://dl.acm.org/doi/pdf/10.5555/3305381.3305498?download=true" target="_blank" rel="noopener">Finn, Chelsea, Pieter Abbeel, and Sergey Levine. “Model-agnostic meta-learning for fast adaptation of deep networks.” Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.</a></p>
<p><a href="https://arxiv.org/pdf/1803.02999.pdf" target="_blank" rel="noopener">Nichol, Alex, Joshua Achiam, and John Schulman. “On first-order meta-learning algorithms.” arXiv preprint arXiv:1803.02999 (2018).</a></p>
<p><a href="http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf" target="_blank" rel="noopener">Snell, Jake, Kevin Swersky, and Richard Zemel. “Prototypical networks for few-shot learning.” Advances in neural information processing systems. 2017.</a></p>
<p><a href="https://openreview.net/pdf?id=rJY0-Kcll" target="_blank" rel="noopener">Ravi, Sachin, and Hugo Larochelle. “Optimization as a model for few-shot learning.” (2016).</a></p>
<p><a href="https://dl.acm.org/doi/pdf/10.5555/3305890.3305945?download=true" target="_blank" rel="noopener">Munkhdalai, Tsendsuren, and Hong Yu. “<mark>Meta networks.</mark>“ Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.</a></p>
<p><a href="http://proceedings.mlr.press/v48/santoro16.pdf" target="_blank" rel="noopener">Santoro, Adam, et al. “<mark>Meta-learning with memory-augmented neural networks.</mark>“ International conference on machine learning. 2016.</a></p>
]]></content>
      <categories>
        <category>Machine Learning Notes</category>
      </categories>
      <tags>
        <tag>Notes</tag>
        <tag>Machine Learning</tag>
        <tag>2020</tag>
      </tags>
  </entry>
  <entry>
    <title>Support Vector Machine</title>
    <url>/2020/05/09/machine_learning_notes_1/</url>
    <content><![CDATA[<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>Classification task is one of the fundamental problems in the field of machine learning. Among all kinds of methods, Support Vector Machine (SVM) plays an essential role. In this blog, I will give a mathematical derivation of SVM.</p>
<a id="more"></a>
<h2 id="PROBLEM-DESCRIPTION"><a href="#PROBLEM-DESCRIPTION" class="headerlink" title="PROBLEM DESCRIPTION"></a>PROBLEM DESCRIPTION</h2><p>The task of classification is that given a set of data points with different labels (e.g. red circles and green triangles shown in the figure below), looking for a decision boundary to separate this dataset. If the dataset is linear separable, we can always find a hyperplane to separate all data.</p>
<p>An existing challenge here is how to make the classifier capable to deal with unseen data. In other words, it means the classifier could be generalized well. From the perspective of SVM, it tries to maximize the fractional margin between data points and the hyperplane, as shown in the figure below.<br><img src="/images/notes/svm_1.png" alt="task"></p>
<p>Given a set of data points ${x_{i},y_{i}}$, where $x_{i}$ is  the feature vector and $y_{i}$ is the label (e.g. ${-1,1}$), the classifier is defined as:<br>$$h_{w,b}(x) = g(w^{T}x+b)$$<br>Where $g(z)$ is a sign function.<br>Then the fractional margin is:<br>$$\gamma_{i} = y_{i}(w^{T}x_{i}+b)$$<br>Here, we also define $\gamma = \min_{i} \gamma_{i}$. Thus the objective function for SVM is:<br>$$\max_{w, b, \gamma} \gamma$$<br>$$s.t. y_{i}(w^{T}x_{i}+b) \ge \gamma, \lVert w \rVert_{2}^{2}=1$$<br>The above objective function means we want to maximize the smallest the fractional margin.</p>
<h2 id="DERIVATION"><a href="#DERIVATION" class="headerlink" title="DERIVATION"></a>DERIVATION</h2><p>The original problem contains a non-convex constraint, meaning that there is no guarantee for the convergence of the optimization process. thus a variation of the original objective function is:<br>$$\max_{w, b, \gamma} \frac{\gamma}{\lVert w \rVert_{2}^{2}}$$<br>$$s.t. y_{i}(w^{T}x_{i}+b) \ge \gamma$$<br>In particular, the term $\frac{\gamma}{\lVert w \rVert_{2}^{2}}$ is also known as geometric margin. Now the constraints are convex but the objective function is still not convex yet. Then if we take a look at $\gamma$, we can impose another constraint here $\gamma = 1$. By doing this it does not really change the objective function, because the extract value of the fractional margin is scaled by the values of parameters of the hyperplane. By scaling, we can always make the minimum fractional margin equal to 1. Then we got the final version of the objective function here:<br>$$\min_{w, b} \frac{1}{2}\lVert w \rVert_{2}^{2}$$<br>$$s.t. y_{i}(w^{T}x_{i}+b)  \ge 1$$</p>
<h2 id="SOLUTION"><a href="#SOLUTION" class="headerlink" title="SOLUTION"></a>SOLUTION</h2><p>A nice way to solve this problem is using the primal-dual algorithm. The origin problem is regarded as the primal problem. By taking the Lagrange multiplier method, we got:<br>$$L (w,b,\alpha) =  \frac{1}{2}\lVert w \rVert_{2}^{2}+\sum_{i}\alpha_{i}(1-y_{i}(w^{T}x_{i}+b))$$<br>Here, we can define:<br>$$\theta_{p}(w,b) = \max_{\alpha, \alpha \ge 0} L(w, b, \alpha)$$<br>Then the primal problem is:<br>$$\min_{w,b} \theta_{p}(w,b) = \min_{w,b} \max_{\alpha, \alpha \ge 0} L(w, b, \alpha)$$<br>Accordingly, we can define:<br>$$\theta_{d}(\alpha) = \min_{w,b} L(w, b, \alpha)$$<br>then we can have our dual problem:<br>$$\max_{\alpha, \alpha \ge 0}  \theta_{d}(\alpha) = \max_{\alpha, \alpha \ge 0}  \min_{w,b} L(w, b, \alpha)$$<br>And dual problem provides a lower bound for the primal problem:<br>$$\min_{w,b} \max_{\alpha, \alpha \ge 0} L(w, b, \alpha) \ge \max_{\alpha, \alpha \ge 0}  \min_{w,b} L(w, b, \alpha)$$<br>And the solution of the dual problem is also the solution of the primal problem when K.K.T. complementary  conditions have been satisfied, which is:<br>$$\alpha_{i}(1-y_{i}(w^{T}x_{i}+b)) = 0$$<br>$$\frac{\partial L(w,b,\alpha)}{\partial w} = 0$$<br>$$\frac{\partial L(w,b,\alpha)}{\partial b} = 0$$<br>Here we got:<br>$$\frac{\partial L(w,b,\alpha)}{\partial w} = w-\sum_{i}\alpha_{i}y_{i}x_{i} = 0$$<br>$$\frac{\partial L(w,b,\alpha)}{\partial b} = -\sum_{i}\alpha_{i}y_{i} = 0$$<br>Plug the value of $w$ back to the Lagrange function:<br>$$L (\alpha) = -\frac{1}{2}\sum_{i}\sum_{j}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{i}^{T}x_{j}+\sum_{i}\alpha_{i}$$<br>Following this, the dual problem is:<br>$$\max_{\alpha}L(\alpha)$$<br>$$s.t. \alpha \ge 0, \sum_{i}\alpha_{i}y_{i} = 0$$</p>
<p>After solving the $\alpha$, it could be plug back to get the value of $w,b$,<br>$$w = \sum_{i}\alpha_{i}y_{i}x_{i}$$<br>$$ b = -\frac{\min_{y_{i} = 1 } w^{T}x_{i} + \max_{y_{i} = -1 } w^{T}x_{i}}{2} $$</p>
<h2 id="TAKE-HOME-QUESTION"><a href="#TAKE-HOME-QUESTION" class="headerlink" title="TAKE HOME QUESTION"></a>TAKE HOME QUESTION</h2><p>HOW TO SOLVE $\alpha$?</p>
]]></content>
      <categories>
        <category>Machine Learning Notes</category>
      </categories>
      <tags>
        <tag>Notes</tag>
        <tag>Machine Learning</tag>
        <tag>Math</tag>
        <tag>Classification</tag>
        <tag>2020</tag>
      </tags>
  </entry>
  <entry>
    <title>A Two-stage Framework for Compound Figure Separation</title>
    <url>/2020/03/28/A-Two-stage-Framework-for-Compound-Figure-Separation/</url>
    <content><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> U2FsdGVkX181LQpWwZnRLPPcETnaUUK42JvNGW/CVGXcjX5PRluNOzzwycuuxJ3oTn9E0JKKtmOn1S8Q97rqQqcsoRD6Jo4yPATwJmWqZqcpqd98Y2rxvWsBUavV/R9H2xx0K6E6g9vv+NQxxvB3RKGx8h42M0Thd6RAmewEMdUEMDe3TW0Loeku1eUTL16HX2RbMgLqSSCsnUUJ4zDLFjgu+D9qF8yOfYKoKlnPK+e/LcqNY9uho76ipsB1Sb7KJVlx/9qFrGbyWDraWZS3Vbmw4tvnj3j0k8lQsDRpGTPhLFrkd58FB9uxhxzm6QDBSsqC+xBmHFw6V799q5YwUiP+VM0TTxBTkR09Q6jq2WInkZmDkoNkLokVsIbTPyAwZaG+Clu5eqkuA4BoJU00YJ0pBlu78zPWvL4/UnManxTrUkoSV9gEluKpQe+1RlZZSJ6p1ggamUvUIaiHXOW5XR6PIGMFT+lQsqV2P5XW/najPfcMRpUAWv6NSyCkOCe0LKt21sMsRq0DrTTFNr7wSOxRe9dcutPUJWtQDtochffxQqUYc/FBCUXkXHVhbgaZ1jPLBDzhDWosM6StjyxAxSziQYD3fpEnQuSolQeySQrJkRx+HB2w/JQ+ypQCSMY5cjpD3kPpeMLmuRLLggUSuZpbhobkIHThBh1LcylScrPIKQIX1Yn5INnXTHVhegutyQkBLvCHom3qv6C+wMxFX5OH5cRr5JBk1YTH+A6Q0DrJ/w1v8mD5EewnGuXuHWizeoVQbpiFmmeJjcrhHXMAkfo4A5adE3Gl6PDWE5VnTdZ2iSWC7vpW9gEfIwC+IcpyfFyU7jchf5FiQ0o0VOfAAPrPhX8ml4nYCN1v0MTrRsKeKO8Zg1+ZGPQH8plSlj2Dc/xM7r5YtB7Og/q/v13zf4vbFWTUyq8/LDciU76lmN4KGiVzv2+/X3kJHFX3Zdmo3fyB42ysvJqZ+x+LyhePv2FXagEvAfevJTW6zDznNxuKI3juo99/VQ3GgMi5g9ziInSy6zXvN9VgZ3yX9htOC0jayPW1KCflG08hC9+Fqh8RSMidqliYdx7nIf8iGfG0EyVenM3c3FUKrKoAnzAiA03nqjMY5HKeCzAe6bPJxxH0VIUulOdEViq/2xZR4+q5Lz90b3pjz0i9PPFZflHq3l7537F5JTUZQpfYubZcyE3oh/XRRX+IsHoay7k4kfoU5SOI+0g8BCLtUz2FTgAHYNVgwzkexO+rKvz6OU1vp5tfEpp4nop87tLvBs3jyhOIns9Hy3igAhN5wySV6A5s9l2vhEC4/rp5UWjEArs+oeu7z9tJPqcfyuqt2TB7Ilzdq+HGQM43pacf6orNmsJCCuWVYsFMUH4n1PXVuauP8r8RLe1PUSaUrdLshChlWheLiXSAy4gHHuobA1HfwbXpkLesrPtMoYH3hNMSqIrvBliF16dClSHuKPXOQ2X7d0jT5HtN6eCvNLVlxwqEJKJVWs0U3M8vpbEKTdD9q15YRlveJ+978Zvf3KZ1/YTTu5iM79EsZ+cvT2W1oqSBN5DaX1vFV4q2T82AvtlFHHmgJiYFDUboFv4/hBpwO4iQ+kQBgZ0PSt5HSFfC+scpLR1oHyPCtHBBozkyd/qRYDNYgpYI6KaLJdXL3wWQzV1/9SIBwacTeFGc2/SmaiLzGFYcdYVEV+j1qH2wFShFXIXvLsnnk04LQm9hR4sHLrB/uGJlTaT47Se/uLIShl6mkzcwX6ZWm9RcKjEM4TgY6h2rxf8eQ2Wr3hWJ1Wfenl6uhjR+QSBNSvxnDh+8qU4u3J5tHQA2/5SIpp61Maa0SL0IZ3G5JLUhlyaewHQ4EdpYd5Nd8UaaDmu1Kxb9BVeU/+MAxB2j+C767hGHWRvveQc0kWlFUgiaaoxDIG1Gs+/PPpj8tncyqKOpvxc2q/xIJ6wl83eyqL+RT9q4OhyRBEVLyrrpxaLGRY0QNF7sXgEyQ+WU4Va6NRp01cBJYldzmuQ4HWr7bzR0DMecolskHVWJgB5Vh3QxkgwRizmVSbziEmb0i43kKkBSc2GgAdQbu3tzqLAtzc9OelD4yvfm0vKHjw2aGoOfLPxU5HGR2OQkJ2ga3gIgWirSX116gfCJNdyFBawbG+fR4e1tr63oXApgbz8yKpGl1lOrhhzPjvaTbFT4GUfrX6S8seDUyUIQ1/0D69RQK+Kz8IgymTaqKLLDWAMWpZMiy4NZrncKyToA6G9DzgaqOkbHUSEJjjadJbYQBx5DOngMuV3lT1QPvHZ894SIhZWbQJgVmBGh3eRc8AcMrw/T6Qg+QK/GoSuErNainVdlOAD4xUOvCMu4It9eH1v7pfRMiJEFV8qBxUYleoipd/1mi8LOXKqUjaLsEQQjNwRh4zFYSnGY+wtr/k8tsvXdwEKL03vyZaTcuSPdsptb/Hbue1XPehRSLfyTGK1r9Q7HLQ+rC3R/1rvFvjSxEzU6sdJpHJDy5U/aUM5tlh+OIgks7NrwkNgII/5n4ZqO4vzDH5UqZ50I6OPCytF+CoCNK2PLOBvq+nkl/gokOrEp+76pbwMLXlGc4Kxnb6EaH766uCHzceMvJSnvipYCHwnjxjqOfsUM8zxVUKWpnn6Ahjv6mlOJyrM2EmKcsURoUxl36XGxlKJrcsnIlRU4ATu66aAg+GrOzJWqJzHkEqlc7Lpzz5gnRjnB4La2rP65wCksq5At2SN4BRR8BgV8kJtoCVgek+bDhdEEfjFe7iOobqu8w6BD7P4FTVZtCL2RwKvQvOWxGHPZZzXZVVS/P4yLWCZSc2J4YgQNmmAuH6pqAvB4sjGH/JHqTgONN3v8D5M+gebwrgou4xFRLVdUvf9lndx+Gn9E1ElruRAiYy5wyeE/OUo5jgzJNjhsqCN07Kd69TK/oJCpdi8xbn8wKfpU2Jgbz39fiiluFW1Z91qgkJZFeP2onCrVnK94Couzv4ZWOGImnByxCwn6d2ZmxMTWlzCStIq+KUsKeC7j+vI45pTlxY7QK/9Ls03TqVFviQRtTs3qY4OX5JUpE6eRql2HCxTnppFad52WhcX0h2zUYTNmVQVf2lBhJbQtl6iwgJ4JBjdoCy3OGg77JpD4V1fhL0suz0jHRy0Wd5NSaxbQXrPb2Umf65IyMGGMCEox9Tf3uuHybFcofnjSo097YB6AsK3RnD5crKkO0VWlp8XpOeq+F4Ldrsxhct+z7WggFaQhieTfaV0YqJRNNLUxd+r8x9XFo108FiZ2K80SDsPkeo3uyUAknXNIqmkmoqMDPQTK4cYOg/P7FFKev82sj02cNlg9SUxZ66N/WfNH4XP7RzlZ58TbhE7DhxHeEAyPMkP7dxMwFMSWb5X4XnG7W3kCoCV9Ppk2NE2NkMFEpq6hyS17OnR98a34kIAcxi4ZM0hEM8Z3OuIM1ATCRfXgNQfJ3l1GYOiSDkhW/EN5JY1ymehfE2fjcZk7D8Cnt2OfKpxv/RcM3zjtuksaiYZhI7HzX5yENmwxAhY5OEYpMcJyVHbrcuq3S4fIizqnaudE4VRm2IbUJcFOPyt0+Xc5leR9U8Ro5vO6CznqHfPbzOEv/VPi6T+RcUf/yPtZYkrP29AnNdfmmwz3eaPgaA55q+DIparWlr1dKSmJ0NEQK0t9YlRYYYN01s7+5GaDAbyEBxHK7sdJws3gI4eWVN+YDPTwxtUg+QLG4/EZqB6EFJcIIMs41QplEs0IslThSLA0QX2c5bJeTvQOxmyzGNaGNeIYj7zCmQuFL+w000pfHosKAxFaSuRgFj80OJaE5Y0ffWp7ElcGMzZSn6mBSyPn9E0eYa7eUUR+1tRgKX78D92oH+H7QuE/O/G7WDgB68ya2W16qFg1JYGeSOSoIESOYCZMVay6YMnGeNPDhcwt1XxllaDwwNUp8XWPxJte3gW5k9vhrO/pNKfiyT9pPonxbxo+j/Uc+OJIvlcWySEf4e0ccmuEConJIGbpRSrP3TpcdVZTHLbNXOzrRC0vfpv/plbrOdnDVC8VXpw1fioR6n7MaOZGWPODVTf2hAt5Cw42uOh45Pxm7Zt9w4Xne+yDQrv+IxXEz4tHTdIlumm08zXQhWHIpIw3A3iNI0+qAiwQwQFpIOutU1+JpQo/z6XwehjIAX5NGTKT9madxHxPt/eZCfbzDgvN/fCkl7D0MWO3PzIXV2rWhYSdwNekXq4jTqVC4jXPXgHAs6+6tTLXwSOzAf0gdFJdVV+OsfTjGVZ+Aec/QKB/JC+tPLSscnjK4ZxR9e36pDtkxmzl8ir5Z5p7hmWgEkgNu87SgxbFMsM5+k8XMTLUVCqMjhW/t7eOM1rek0Gs3qjKpsu65yksnGPFYaKGEaC62uZx3PeEOxIbO5NIIEMEy1Hx4hXTmuTNHwz/6GgbuUG+5/iNkf6YSQtofQgUjsTRkLto1fFG1KPqM764jWbcrjRxuR1UiqXr+D3lyz0dc+PXdAxHeI8j/VyfNuHXV6nq8kHahSXvVpvCWDreHvAd0mwW16LJKzXPrdbpUP9ree50fGCcW2NDp7ib55EH/XoT0xj5K9XH3rGzBke593qeMcKNhpkr5be2iHTz2T6qu4zddLVU8m5o7wtH/mKMz6pJlXmTWetEFRj/FIZYrIAsIjAD/ezl9nIn6+Q/jVhe6zNlfvnbcj3jEQ1uX1GOK5sCkjXzKfXvISV5O7ODrbRXfv8S002iXGfxI3Jxzi4Jk1sFSOYZXDfDnIh0IKMjdxpoKHY8p/iDj+sD5sMIx6+A7v07tJeEpi3j9C/Ug5wfo7c+5ZnRAB4u4HdE7FY+3Sl2prFIGoTIlY2bNBWpRT0KtvsaL386kdpW+Ff3A+zdgH1/JhVGYEVLurFuPakI88TzXG6qLUOTBYFbl7dWyLFqRVH6i1v3c82aAqp6dcaLbrZYp/Ro2kiVwzZy+yAJhDgHLYT3M0ekiwTAsxs310t2ascY8/zBdd2veKpKZ7qu0d5fD1KZxAGvSwUuK+33o7oDnyZ+3n+qkzMSkPyneMAitOtd9W6yNB9ywfP8NhPRD8tjH8gucBmV9HdK5sMlXT/mQJv5VA8sB31JDCQRpzFpUoI/u4rEvn/nZz0OVTytFmm8t7KrJ/6sUk5emGcmWqHxG4IybfnaVK79wfBdtzJwkQTK0hEJI8zGnMQhHpYc2WdAbcFv8N7taiGJX6RnC58YpvN+EaeuKgQ23oj2/DvEPWA8ClsV9TzuYvKLRsOmVE2Rjw7tzpx/jaqFu8kGU2whwDvnb5Fj5gTJjgvYSyjy2ZhvLJMS/eVdNzyuNEE2Zg5smlyPH1Tgt10TxBW9Oocp53M8GLIa10f+uZzxt3Hdw+TXLaygiRXh9JxphAlUmp5BJv5ms4OyJy6c3+4FgEf3gI8y+8T2HwnjFMm0Ph6KKApyjHdPAjZlJbxbVckRXEEZ4EjVoTwDD5IdNBF+b24CMeBCJuTVmPc3NITR76Su1BPdyjJLmVbXhRNYGnOpdztKycfOr+qwIMzCfXncB30ZHQA/dX0J/s7O1SbCypIrMz+Jq3mwGX81tguICNAL5T0hJXEx9ljrmzdyfU/ntUW1HR2j2DuWJS1g7AyuKLTD7qzfh0pkW2Ub3bMX2LgK3Ag/boRpjx09b1KMEL0BwB0IG0bFyZbp40bj8JQFBFMpVLeV352kRmGwlNXAf9+0dJBmhRt6c0UlbqfW2d2R2imh3905gwuOiBZNI/hLZWf5JyMQG7eH/+qNc8pdWyJBJuO8cXd9tml4NKyYQnaO203diq4ajyzfug1FSa7i5iPGx5IP9VsIjgGdRff9fFSJDdh+1xd/fK58ClHhCwtmJ8tBOAr8CB6BiNBxSU0Xl9cnJHSjwJSYnuWx5bdl4dAjO6CrYg2SgyQXuserfM6tCtza1CHr3B3KaEqm4WydOTDkqFHKvJqEnLxTSmunzcxKXez5w5NiRoTbQIFdVjEIiwNGBfgJBg03cYGEJosBUwCBL/cNO97w/mivMB8F1czTlULDaXER5yKF4+If5QjUHczwkdPKnPPTzSh2FjIpQwuQa/M0Ul7PKOQYkOGcCSVUuAu8SMa2X593cKy0R3aEKZEt3WQa9FTPpKUUBiyZCixsODRObVrUKa+AXP5Dk90VJGuo/Ws3h6yl71QMNbeL/ltW1qmSYKi3Q6IyueXR8UvkwqHSsLbFLM8PrCLxOnNjgK6GhC3QjbPgKEty58GZv/Svo0Ycfw+yGGOt+9llxnAtEAR6RCrXR5bejkflpsIFOSFIErxEA2wJgViQZCV3U+oaZ7dcsDQxKa/Yq04QCd8ueKsc8IuVRts8DrjXiFoIYowDN+F6d/HbKVPsuCq/YmonYjyMzJUqyniGgCo6vY2ExgfCIWxwlI/ofaEFWrWMym0FV5y/QWOu9jfaXONbCT03cDeW4UhA7/9I8W4yWoZ/QWPvIpkUn0+5yEp7Vhq86FYb3ItjGwLH8j8Jw0dlIXYw1y7rnhnaNuUS+/3kdOa6itMpNwLasjYg40FT+Eb4KLh8N4CvTRbEUl1u7hpwNZe26BB5aZQKDS9TZUzPpmaphH8/D/8Sh/Mg7lSUxYNdv+dKTdHVTAdCyCQtxA4rbPLJC2VoWtvJg4H8IV1VGCwgV1wIaWhjLQ7dip4cwPW/E7tr2hkF/1dIifPMVJYoGxW2on1rPS2QQztVDAFrtIUzHu9tp2jq8mt8nh3TnqAeJ0j2uiKU3hVX5kzuUmS0QhRo4VnCQF3z6EoA1MKYOeuoWH+lv01SI1/E6UEf8vilhSryB6YsRbwqaysyWtNYPH7LNkRPp4vu0bWa6mdZxS8hHYem7qXRcq+N6Opz/1zZogOQphYRNSWfpoEIVFvl4zyhrP+4e5UBjW65VzFtmGl14P9mY3Pmr1uM0/QHgr6i0IaYkZyH1wE0BWWndm6+XgplHQxecfuwPTjXsnhS7FQ2r8QSctAcFe5SsdjS+bC7EBQf0VJqScbAepM98mQLTuW5LboVopphuejoKPwBOxSsNCYUQDNLGq2vRkQ1TNPjmF9pF3yM0txcp34QhpDikrm52H2jL11Oc8nbllxTsDmxrh1OEkoFnHlEjWTM7W1y5QJNUSzyQM+34KJuOSfBVuZWaxvKgvB3eusWL9dgxmxByXfh3VIDQIw+owyRQ7VisBb6O8X1LYWxo9aHTu66BKlZzBg875+qxjCiXn7rrFCFGBN6CvRJmKt6YsfymsTYsyeAE2cG2qS8oXDThSB+xLxTcUn3gqOBieWW1nQkf7BEau69AwsmKevLHNnWWEz8+pvYJALj8K4iARELU1w68yFvRkgDvQUaGxNWsAHZSJTrjY6d8YYBqTXZ+redmBFDRySB+qq2+3+8Lgd7qAB4AayfAtDJYAeIk1DhbpDtRRnyQuY3/Tx5vEcDWwIVGRH0cVhx7nYWfuS2OrVvl/6AED/MAGUox17mjk+pdcUNAKYozSQvwuAXkt0Q6+PFgxpFZUWDmj1amTHxT75on7MKYEwWFT1aVZMk0Qv6p450LrH4LZu32sGjxRk2XwfVoR7hJDP5S6gir84R5T61BTK1EGeRdf5nDK7SiKS/J+wy8wbqH2qCgCornYYg6C1tHIXI4Umz4BAgAAkPrCs7OINSsdctZ3iIKuJjtnVYlrPjYZ4x3vA2H9NwKj9Nj56WKzM6HHcg1Y7v73Ra4lixJ53c5QVe3AKp3vU2RUT3xSvXlN87/GQLLUpQEUpZfSsqI3pvu92bQ0YCH+RfzRTuiTIodHZhuBghaIhss2t/xOpvJ+SunoDyohfXW02BO4t94qIL+nm7SMrbcQSU1w/vyrgYaL95x8ggvdPBOU0KKbFVnbzEKCmaPyijTCo+3GxuxvFUNR5K6S4YVQw2HsllJd1JQeK9DVg8nf7XdU/xN6sAfOruuv2IZJhbLdkaqshVx6+LQwQ7k3sd7xzBD8h0tGm7bDgDllwLiHf57xczwHd8eDYFD6I3bsCMIMnVkixtE+6nl25iE+QMAkNzaFxN/zKpw4TcyoQptQSxxG7ezqcQMhuE9rM5GlbCcrQqjqNCu4KC7r6tVPrjZR5qYcPjLc3IEPTCm+yKxagStVuHR/U4pJfxCfK1Bq15EE7zmmT0CE3mL1MTF5nuTDIDtSihS1Jm/DqdNaaY62Wf6UWbPz0hDpL9kj/wuI6R2ByW2dbLo9mDxKjHSE7+QBnJ+alioyp0/HyqQEliIpgcFC4pT55pInsdyxoz7rDW3Iy9oD2N8xGimJWnd/0r2DjPIdSHZtvvHkQXFXQehyxPjn1/cdbOyhpMNM4fouslJH7JL2oZdX49umcO/B0A0hfo9htXs3k1gD4qbeAEwAIF0pS8V44+4Ery2Uw0vLV3gQvydtVSTRcQVsKCLcorZweKIN0tC9b6usJX5ibmKn97HHhZ7gUgn1TUBxv2HT6po9fLo4gHKN0tpzj640RhgmxdIc/7lufSt+WoCkC17+QtLRjB87SPX9hgh1PgNP902o5WxGOh9iJHhTIjXKUXt4viRxwbnEoshexYSHhunCgpBYlo7N5VpfrdfwIT1Spim4bQ3Kah0c07O56bKEhPg4k7R5WW+BVqhZLy4m0lLZOOU0Bs73AtlgBJfoH9PwXvX6REjbGNF1GJBwH2tZBhFUlQeyC5Ov7EJwODRz73VnOvCh4G/PqiQ8qnBvGQxsmOXc/o/W3whWaZYmTVlQVuABH8O49BUeyqmAK2E2S76decKKT9c4c3LIaD/czoaHuWsW61Oo8Cnddkcp/ff1LYJXsA59qYhw29eAlv4UrCH8c9et6B+qdNrqV6ZXNqsGjVW7IYu7SalHt18rxWKm2lPVeRcR5EpuY0cof64fDUGxkbMZIivQdSj1ON7u6JWWAGJ6om94zV7LBSsegWT85OwBRVcoKrxNLsRGJLVwGkon571AJRTC5G0vORjF1oV95hOmstpReTX2KwiHWQXUFvOD/fNFFeraD360mQnhu7SZhPQ7XWRdgk2pBpcRmETvffyImDW16YvOmosHwWTrnQLV3KDoNHZWYeim4gsmqSz3Ku4FWWs4BiUZc08rx8NxFCWijeBnF1xAt1lo2DK1IO5BXwiq3jxpqcZyqJt1QCvNF8v8U0B5B+/kR+KxHFkOa4AxyH2OZaGhZiRW7/SmHEqXUwsePeHS2SeQ6MzqNBv72zIoMg8Od48xSOzS7Rq9SURnP/8VXQq5hZ7cHv6yQUqD4arfggUTYyWjFW5dlYEyqm9J0dbbjxBOuhN6eh+WvQTYH313k= </div>]]></content>
      <categories>
        <category>Conference Paper</category>
      </categories>
      <tags>
        <tag>2020</tag>
        <tag>Deep Learning</tag>
        <tag>Object Detection</tag>
        <tag>ICME</tag>
        <tag>Workshop</tag>
        <tag>REVIEWS</tag>
      </tags>
  </entry>
  <entry>
    <title>Welcome to Weixin&#39;s Personal Homepage</title>
    <url>/2020/03/18/hello-world/</url>
    <content><![CDATA[<p>I am currently a third-year PhD student in the department of computer science at Northwestern University, working with Prof. Oliver Cossairt in Computational Photography Lab. My research focus on computer vision, deep learning and image processing. Before this, I received my master degree and bachelor degree in the department of automation from Tsinghua University in 2017 and 2014, respectively.</p>
<h2 id="NEWS"><a href="#NEWS" class="headerlink" title="NEWS:"></a>NEWS:</h2><p><a href="/2020/05/09/machine_learning_notes_1/">Derivation for Support Vector Machine</a></p>
]]></content>
      <categories>
        <category>Resume</category>
      </categories>
  </entry>
</search>
